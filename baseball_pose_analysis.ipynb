{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd2f1173-d918-4c0b-8cc8-71efd76ed7c0",
   "metadata": {},
   "source": [
    "# Defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810148b8-c406-40c5-8938-0987a7a83ad0",
   "metadata": {},
   "source": [
    "## 비디오 뼈대"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea4f142-db2e-4b21-b456-267702bc0e89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c59be23-3a1f-436a-80bd-48779d32c5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import os\n",
    "import sys\n",
    "import mediapipe as mp\n",
    "import c3d # C3D library import\n",
    "import open3d as o3d # Open3D 임포트\n",
    "import time # time 모듈 임포트\n",
    "from filterpy.kalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b45109-fc51-4ea7-97c1-a57d502f3331",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 전역 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "798934b0-344f-4275-afa8-4453e360fe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Global MediaPipe and Landmark Mappings ---\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "model_complexity = 2\n",
    "min_detection_confidence = 0.9\n",
    "min_tracking_confidence = 0.9\n",
    "min_draw_visibility = 0.2\n",
    "\n",
    "apply_kalman_filter = True\n",
    "kalman_filter_process_noise_std=0.001\n",
    "kalman_filter_measurement_noise_std = 0.05\n",
    "output_dir = 'result_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3849cdb9-26bc-40ba-a320-7d8bc1c45a3f",
   "metadata": {},
   "source": [
    "#### 그림용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "955abc3a-dbee-44e5-839c-629fa26240c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe Landmark Names for C3D Marker Mapping\n",
    "MEDIAPIPE_LANDMARK_NAMES = {\n",
    "    mp_pose.PoseLandmark.NOSE.value: 'NOSE',\n",
    "    mp_pose.PoseLandmark.LEFT_EYE_INNER.value: 'L_EYE_INNER',\n",
    "    mp_pose.PoseLandmark.LEFT_EYE.value: 'L_EYE',\n",
    "    mp_pose.PoseLandmark.LEFT_EYE_OUTER.value: 'L_EYE_OUTER',\n",
    "    mp_pose.PoseLandmark.RIGHT_EYE_INNER.value: 'R_EYE_INNER',\n",
    "    mp_pose.PoseLandmark.RIGHT_EYE.value: 'R_EYE',\n",
    "    mp_pose.PoseLandmark.RIGHT_EYE_OUTER.value: 'R_EYE_OUTER',\n",
    "    mp_pose.PoseLandmark.LEFT_EAR.value: 'L_EAR',\n",
    "    mp_pose.PoseLandmark.RIGHT_EAR.value: 'R_EAR',\n",
    "    mp_pose.PoseLandmark.MOUTH_LEFT.value: 'L_MOUTH',\n",
    "    mp_pose.PoseLandmark.MOUTH_RIGHT.value: 'R_MOUTH',\n",
    "    mp_pose.PoseLandmark.LEFT_SHOULDER.value: 'L_SHOULDER',\n",
    "    mp_pose.PoseLandmark.RIGHT_SHOULDER.value: 'R_SHOULDER',\n",
    "    mp_pose.PoseLandmark.LEFT_ELBOW.value: 'L_ELBOW',\n",
    "    mp_pose.PoseLandmark.RIGHT_ELBOW.value: 'R_ELBOW',\n",
    "    mp_pose.PoseLandmark.LEFT_WRIST.value: 'L_WRIST',\n",
    "    mp_pose.PoseLandmark.RIGHT_WRIST.value: 'R_WRIST',\n",
    "    mp_pose.PoseLandmark.LEFT_PINKY.value: 'L_PINKY',\n",
    "    mp_pose.PoseLandmark.RIGHT_PINKY.value: 'R_PINKY',\n",
    "    mp_pose.PoseLandmark.LEFT_INDEX.value: 'L_INDEX',\n",
    "    mp_pose.PoseLandmark.RIGHT_INDEX.value: 'R_INDEX',\n",
    "    mp_pose.PoseLandmark.LEFT_THUMB.value: 'L_THUMB',\n",
    "    mp_pose.PoseLandmark.RIGHT_THUMB.value: 'R_THUMB',\n",
    "    mp_pose.PoseLandmark.LEFT_HIP.value: 'L_HIP',\n",
    "    mp_pose.PoseLandmark.RIGHT_HIP.value: 'R_HIP',\n",
    "    mp_pose.PoseLandmark.LEFT_KNEE.value: 'L_KNEE',\n",
    "    mp_pose.PoseLandmark.RIGHT_KNEE.value: 'R_KNEE',\n",
    "    mp_pose.PoseLandmark.LEFT_ANKLE.value: 'L_ANKLE',\n",
    "    mp_pose.PoseLandmark.RIGHT_ANKLE.value: 'R_ANKLE',\n",
    "    mp_pose.PoseLandmark.LEFT_HEEL.value: 'L_HEEL',\n",
    "    mp_pose.PoseLandmark.RIGHT_HEEL.value: 'R_HEEL',\n",
    "    mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value: 'L_FOOT_INDEX',\n",
    "    mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value: 'R_FOOT_INDEX',\n",
    "}\n",
    "\n",
    "ALL_POSE_LANDMARK_INDICES = list(range(len(mp_pose.PoseLandmark)))\n",
    "ALL_POSE_MARKER_NAMES = [MEDIAPIPE_LANDMARK_NAMES.get(i, f'UNKNOWN_{i}') for i in ALL_POSE_LANDMARK_INDICES]\n",
    "\n",
    "# --- Color Definitions for Drawing ---\n",
    "COLOR_LEFT_ARM = (255, 0, 0)     # Blue (Left Arm)\n",
    "COLOR_RIGHT_ARM = (0, 0, 255)    # Red (Right Arm)\n",
    "COLOR_LEFT_LEG = (255, 255, 0)   # Cyan (Left Leg)\n",
    "COLOR_RIGHT_LEG = (0, 255, 255)  # Yellow (Right Leg)\n",
    "COLOR_TORSO = (0, 255, 0)        # Green (Torso)\n",
    "COLOR_HEAD_NECK = (255, 255, 255) # White (Head/Neck)\n",
    "\n",
    "# Map connections to their respective colors\n",
    "CONNECTIONS_COLORS = {\n",
    "    # Arms\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_ELBOW.value): COLOR_LEFT_ARM,\n",
    "    (mp_pose.PoseLandmark.LEFT_ELBOW.value, mp_pose.PoseLandmark.LEFT_WRIST.value): COLOR_LEFT_ARM,\n",
    "    (mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_ELBOW.value): COLOR_RIGHT_ARM,\n",
    "    (mp_pose.PoseLandmark.RIGHT_ELBOW.value, mp_pose.PoseLandmark.RIGHT_WRIST.value): COLOR_RIGHT_ARM,\n",
    "    \n",
    "    # Legs\n",
    "    (mp_pose.PoseLandmark.LEFT_HIP.value, mp_pose.PoseLandmark.LEFT_KNEE.value): COLOR_LEFT_LEG,\n",
    "    (mp_pose.PoseLandmark.LEFT_KNEE.value, mp_pose.PoseLandmark.LEFT_ANKLE.value): COLOR_LEFT_LEG,\n",
    "    (mp_pose.PoseLandmark.LEFT_ANKLE.value, mp_pose.PoseLandmark.LEFT_HEEL.value): COLOR_LEFT_LEG,\n",
    "    (mp_pose.PoseLandmark.LEFT_HEEL.value, mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value): COLOR_LEFT_LEG,\n",
    "    (mp_pose.PoseLandmark.RIGHT_HIP.value, mp_pose.PoseLandmark.RIGHT_KNEE.value): COLOR_RIGHT_LEG,\n",
    "    (mp_pose.PoseLandmark.RIGHT_KNEE.value, mp_pose.PoseLandmark.RIGHT_ANKLE.value): COLOR_RIGHT_LEG,\n",
    "    (mp_pose.PoseLandmark.RIGHT_ANKLE.value, mp_pose.PoseLandmark.RIGHT_HEEL.value): COLOR_RIGHT_LEG,\n",
    "    (mp_pose.PoseLandmark.RIGHT_HEEL.value, mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value): COLOR_RIGHT_LEG,\n",
    "\n",
    "    # Torso\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_SHOULDER.value): COLOR_TORSO,\n",
    "    (mp_pose.PoseLandmark.LEFT_HIP.value, mp_pose.PoseLandmark.RIGHT_HIP.value): COLOR_TORSO,\n",
    "    (mp_pose.PoseLandmark.LEFT_SHOULDER.value, mp_pose.PoseLandmark.LEFT_HIP.value): COLOR_TORSO,\n",
    "    (mp_pose.PoseLandmark.RIGHT_SHOULDER.value, mp_pose.PoseLandmark.RIGHT_HIP.value): COLOR_TORSO,\n",
    "    \n",
    "    # Head/Neck (Nose to shoulders to represent neck for simplified face)\n",
    "    (mp_pose.PoseLandmark.NOSE.value, mp_pose.PoseLandmark.LEFT_SHOULDER.value): COLOR_HEAD_NECK, \n",
    "    (mp_pose.PoseLandmark.NOSE.value, mp_pose.PoseLandmark.RIGHT_SHOULDER.value): COLOR_HEAD_NECK,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b53ef5-d69e-493b-8e42-05bd9f2a5a30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ab3f9a-87d4-42a2-940b-40b50af7a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3D 랜드마크 시각화 함수 (Open3D 사용) ---\n",
    "def visualize_3d_landmarks_animation(all_frames_3d_landmarks, connections, fps):\n",
    "    \"\"\"\n",
    "    수집된 3D 랜드마크 데이터를 Open3D를 사용하여 애니메이션으로 시각화합니다.\n",
    "\n",
    "    Args:\n",
    "        all_frames_3d_landmarks (list): 각 프레임의 3D 랜드마크 (Numpy 배열 리스트).\n",
    "                                        각 배열은 (num_markers, 3) 형태. (미터 단위)\n",
    "        connections (list): 랜드마크 연결 정보를 담은 튜플 리스트 (예: [(0, 1), (1, 2)]).\n",
    "                            MediaPipe의 PoseLandmark.value 인덱스를 사용.\n",
    "        fps (float): 시각화 속도를 조절하기 위한 초당 프레임 수.\n",
    "    \"\"\"\n",
    "    if not all_frames_3d_landmarks:\n",
    "        print(\"시각화할 3D 랜드마크 데이터가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # Open3D는 기본적으로 밀리미터 단위를 선호하지만, 여기서는 MediaPipe의 미터 단위를 그대로 사용합니다.\n",
    "    # 필요하다면 여기서 * 1000.0 하여 밀리미터로 변환할 수 있습니다.\n",
    "    # 예를 들어: initial_landmarks = all_frames_3d_landmarks[0] * 1000.0\n",
    "\n",
    "    # 첫 프레임의 랜드마크로 초기 포인트 클라우드 및 라인셋 생성\n",
    "    initial_landmarks = all_frames_3d_landmarks[0] # (num_markers, 3) 형태\n",
    "\n",
    "    # 포인트 클라우드 객체 생성\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(initial_landmarks)\n",
    "    # 모든 랜드마크를 빨간색으로 표시\n",
    "    pcd.colors = o3d.utility.Vector3dVector(np.array([[1.0, 0.0, 0.0] for _ in range(initial_landmarks.shape[0])]))\n",
    "\n",
    "    # 라인셋 객체 생성 (Open3D는 라인을 나타내기 위해 [point_idx1, point_idx2] 형태의 리스트를 원함)\n",
    "    lines = []\n",
    "    line_colors = [] # 각 연결선에 대한 색상 리스트\n",
    "    for c_tuple in connections:\n",
    "        lines.append([c_tuple[0], c_tuple[1]]) # 연결선의 점 인덱스 추가\n",
    "        \n",
    "        # 미리 정의된 CONNECTIONS_COLORS 딕셔너리에서 색상을 찾아 적용\n",
    "        mapped_color = None\n",
    "        for conn_key, color_rgb in CONNECTIONS_COLORS.items():\n",
    "            # 양방향 연결을 모두 고려 (예: (11, 13) 또는 (13, 11))\n",
    "            if (conn_key[0] == c_tuple[0] and conn_key[1] == c_tuple[1]) or \\\n",
    "               (conn_key[0] == c_tuple[1] and conn_key[1] == c_tuple[0]):\n",
    "                mapped_color = [x / 255.0 for x in color_rgb] # RGB를 0-1 범위로 정규화\n",
    "                break\n",
    "        line_colors.append(mapped_color if mapped_color else [1.0, 1.0, 1.0]) # 기본값은 흰색\n",
    "\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "        points=o3d.utility.Vector3dVector(initial_landmarks), # 초기 점 데이터\n",
    "        lines=o3d.utility.Vector2iVector(lines) # 연결 정보\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(np.array(line_colors))\n",
    "\n",
    "    # Open3D 시각화 도구 설정\n",
    "    vis = o3d.visualization.Visualizer()\n",
    "    vis.create_window(window_name='3D Pose Animation', width=1024, height=768)\n",
    "    \n",
    "    # 초기 지오메트리 (포인트 클라우드와 라인셋)를 뷰어에 추가\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.add_geometry(line_set)\n",
    "\n",
    "    # 뷰 컨트롤 설정 (선택 사항: 초기 카메라 위치 및 줌 조정)\n",
    "    ctr = vis.get_view_control()\n",
    "    ctr.set_zoom(0.8) # 줌 레벨 조정\n",
    "    # 초기 카메라 방향 설정 (예: 정면에서 바라보게)\n",
    "    # ctr.set_front([0, 0, -1]) # Z 축 방향으로 앞을 바라봄\n",
    "    # ctr.set_up([0, 1, 0])     # Y 축이 위를 향함\n",
    "    # ctr.set_lookat([0, 0, 0]) # 원점을 중심으로 바라봄\n",
    "\n",
    "    # 애니메이션 루프\n",
    "    # 비디오의 FPS에 맞춰 프레임 간 지연 시간 설정\n",
    "    delay_per_frame = 1.0 / fps if fps > 0 else 0.01 \n",
    "\n",
    "    print(\"3D 시각화를 시작합니다. 창을 닫으면 종료됩니다.\")\n",
    "    for i, frame_landmarks_3d in enumerate(all_frames_3d_landmarks):\n",
    "        # 포인트 클라우드와 라인셋의 점 데이터를 현재 프레임의 랜드마크로 업데이트\n",
    "        pcd.points = o3d.utility.Vector3dVector(frame_landmarks_3d)\n",
    "        line_set.points = o3d.utility.Vector3dVector(frame_landmarks_3d) # 라인셋도 점 데이터를 업데이트해야 함\n",
    "\n",
    "        # 업데이트된 지오메트리를 뷰어에 반영\n",
    "        vis.update_geometry(pcd)\n",
    "        vis.update_geometry(line_set)\n",
    "        \n",
    "        # 사용자 인터랙션 (마우스 회전, 확대/축소 등) 처리\n",
    "        vis.poll_events()\n",
    "        # 렌더링 업데이트 (화면을 다시 그림)\n",
    "        vis.update_renderer()\n",
    "\n",
    "        # 프레임 속도에 맞춰 잠시 대기\n",
    "        time.sleep(delay_per_frame)\n",
    "\n",
    "    vis.destroy_window() # 모든 프레임을 표시한 후 시각화 창 닫기\n",
    "    print(\"3D 시각화가 종료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f692b584-6690-4ae0-a649-2970b7759787",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_custom(image, landmarks, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Draws custom-styled pose landmarks on the image.\n",
    "    - Simplifies face to a single nose node.\n",
    "    - Draws other body points as small gray dots.\n",
    "\n",
    "    Args:\n",
    "        image (np.array): The OpenCV BGR image frame to draw on.\n",
    "        landmarks (mediapipe.framework.formats.landmark_pb2.NormalizedLandmarkList):\n",
    "                    The pose landmarks detected by MediaPipe.\n",
    "        image_width (int): Width of the image.\n",
    "        image_height (int): Height of the image.\n",
    "    \"\"\"\n",
    "    for idx, landmark in enumerate(landmarks.landmark):\n",
    "        # Only draw if landmark visibility is good\n",
    "        if landmark.visibility < min_draw_visibility:\n",
    "            continue\n",
    "        \n",
    "        center_coordinates = (int(landmark.x * image_width), int(landmark.y * image_height))\n",
    "\n",
    "        if idx == mp_pose.PoseLandmark.NOSE.value: # Nose: single face node\n",
    "            cv2.circle(image, center_coordinates, 5, (255, 255, 255), -1) # White circle\n",
    "        elif 1 <= idx <= 10: # Other facial landmarks (eyes, ears, mouth): don't draw\n",
    "            pass\n",
    "        else: # Body, arm, leg landmarks: small gray dot\n",
    "            cv2.circle(image, center_coordinates, 2, (100, 100, 100), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b6ffe1a-18a8-4ffc-a880-c659297c063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_connections_custom(image, landmarks, image_width, image_height):\n",
    "    \"\"\"\n",
    "    Draws custom color-coded pose connections (bones) on the image.\n",
    "\n",
    "    Args:\n",
    "        image (np.array): The OpenCV BGR image frame to draw on.\n",
    "        landmarks (mediapipe.framework.formats.landmark_pb2.NormalizedLandmarkList):\n",
    "                    The pose landmarks detected by MediaPipe.\n",
    "        image_width (int): Width of the image.\n",
    "        image_height (int): Height of the image.\n",
    "    \"\"\"\n",
    "    for connection in mp_pose.POSE_CONNECTIONS:\n",
    "        idx1, idx2 = connection\n",
    "        \n",
    "        if landmarks.landmark[idx1].visibility < min_draw_visibility or landmarks.landmark[idx2].visibility < min_draw_visibility:\n",
    "            continue\n",
    "        \n",
    "        # Get color for the connection from the predefined map\n",
    "        color = CONNECTIONS_COLORS.get(connection, None)\n",
    "        if color is None: # Check if tuple order is reversed in map\n",
    "            color = CONNECTIONS_COLORS.get((idx2, idx1), None)\n",
    "\n",
    "        if color is not None:\n",
    "            point1 = (int(landmarks.landmark[idx1].x * image_width), int(landmarks.landmark[idx1].y * image_height))\n",
    "            point2 = (int(landmarks.landmark[idx2].x * image_width), int(landmarks.landmark[idx2].y * image_height))\n",
    "            cv2.line(image, point1, point2, color, 2) # Line thickness 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafb9d9d-7342-4eb4-ad0f-83ab49c69297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_pose_on_frame(frame, pose_landmarks):\n",
    "    \"\"\"\n",
    "    Orchestrates drawing pose landmarks and connections on a frame with custom styling.\n",
    "\n",
    "    Args:\n",
    "        frame (np.array): The OpenCV BGR image frame.\n",
    "        pose_landmarks (mediapipe.framework.formats.landmark_pb2.NormalizedLandmarkList):\n",
    "                        The pose landmarks detected by MediaPipe.\n",
    "\n",
    "    Returns:\n",
    "        np.array: The frame with the custom-drawn pose.\n",
    "    \"\"\"\n",
    "    frame_with_pose = frame.copy()\n",
    "    h, w, _ = frame.shape\n",
    "    \n",
    "    # Call functions to draw landmarks and connections\n",
    "    draw_landmarks_custom(frame_with_pose, pose_landmarks, w, h)\n",
    "    draw_connections_custom(frame_with_pose, pose_landmarks, w, h)\n",
    "    \n",
    "    return frame_with_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e090831a-7232-488e-99b2-7db8124ce62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_c3d(output_filename, all_frames_3d_landmarks, fps, marker_names):\n",
    "    if not all_frames_3d_landmarks:\n",
    "        print(\"내보낼 3D 랜드마크 데이터가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    num_frames = len(all_frames_3d_landmarks)\n",
    "    num_markers = all_frames_3d_landmarks[0].shape[0]\n",
    "\n",
    "    points_data_all_frames = np.array(all_frames_3d_landmarks) * 1000.0 # meters to millimeters\n",
    "\n",
    "    writer = c3d.Writer()\n",
    "\n",
    "    for frame_idx in range(num_frames):\n",
    "        current_frame_points_3d = points_data_all_frames[frame_idx]\n",
    "\n",
    "        residuals_column = np.zeros((num_markers, 1), dtype=np.float32)\n",
    "\n",
    "        points_with_residuals = np.hstack((current_frame_points_3d, residuals_column))\n",
    "        points_with_residuals = np.hstack((points_with_residuals, residuals_column))\n",
    "\n",
    "        writer.add_frames([(points_with_residuals, np.array([]))])\n",
    "\n",
    "    with open(output_filename, 'wb') as handle:\n",
    "        writer.write(handle)\n",
    "\n",
    "    print(f\"총 {num_frames} 프레임을 {output_filename}으로 성공적으로 내보냈습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd530eda-5615-46ce-b121-fb910df9626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_bone(frame, frame_with_pose):\n",
    "    \"\"\"\n",
    "    Extracts only the drawn pose (bones and landmarks) from the frame.\n",
    "\n",
    "    Args:\n",
    "        frame (np.array): The original BGR image frame.\n",
    "        frame_with_pose (np.array): The frame with pose, name, etc. drawn on it.\n",
    "\n",
    "    Returns:\n",
    "        np.array: A new frame containing only the drawn pose.\n",
    "    \"\"\"\n",
    "    final_pose_only_frame = np.zeros_like(frame)\n",
    "    # Compare pixels: if they're different, it means something was drawn.\n",
    "    identical_pixels_mask = np.all(frame == frame_with_pose, axis=2)\n",
    "    # Copy only the pixels that are different (where pose or name was drawn)\n",
    "    final_pose_only_frame[~identical_pixels_mask] = frame_with_pose[~identical_pixels_mask]\n",
    "    return final_pose_only_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb8b778-6c63-40b6-8d73-9ac34aae3ee7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3D 인터랙티브 시각화 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a394fb04-4963-4cee-bc4a-e29b36edaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractivePoseVisualizer:\n",
    "    def __init__(self, all_frames_3d_landmarks, connections, initial_fps):\n",
    "        if not all_frames_3d_landmarks:\n",
    "            raise ValueError(\"시각화할 3D 랜드마크 데이터가 없습니다.\")\n",
    "\n",
    "        self.all_frames_3d_landmarks = all_frames_3d_landmarks\n",
    "        self.num_frames = len(all_frames_3d_landmarks)\n",
    "        self.connections = connections\n",
    "\n",
    "        self.current_frame_idx = 0\n",
    "        self.is_playing = False\n",
    "        self.playback_speed_factor = 1.0\n",
    "        self.base_frame_delay = 1.0 / initial_fps if initial_fps > 0 else 0.033\n",
    "        self.update_frame_delay()\n",
    "\n",
    "        self.app = o3d.visualization.gui.Application.instance\n",
    "        self.app.initialize()\n",
    "\n",
    "        self.window = self.app.create_window(\"3D Interactive Pose Animation\", 1024, 768)\n",
    "\n",
    "        self.scene_widget = o3d.visualization.gui.SceneWidget()\n",
    "        self.scene_widget.scene = o3d.visualization.rendering.Open3DScene(self.window.renderer)\n",
    "        self.window.add_child(self.scene_widget)\n",
    "\n",
    "        self.window.set_on_layout(self._on_layout)\n",
    "\n",
    "        all_landmarks_flat = np.vstack(self.all_frames_3d_landmarks)\n",
    "        self.scene_bbox = o3d.geometry.AxisAlignedBoundingBox.create_from_points(o3d.utility.Vector3dVector(all_landmarks_flat))\n",
    "\n",
    "        self.scene_widget.setup_camera(1.0, self.scene_bbox, [0, 0, -1])\n",
    "\n",
    "        self.scene_widget.scene.set_background([0.1, 0.1, 0.1, 1.0])\n",
    "\n",
    "        self.pcd_name = \"landmarks_pcd\"\n",
    "        self.line_set_name = \"connections_line_set\"\n",
    "\n",
    "        self.point_cloud_geometry = None\n",
    "        self.line_set_geometry = None\n",
    "\n",
    "        self._initialize_geometry()\n",
    "\n",
    "        self.window.set_on_key(self._on_key_event)\n",
    "\n",
    "        print(\"\\n--- 3D 인터랙티브 포즈 애니메이션 조작 방법 ---\")\n",
    "        print(\"  Spacebar: 재생/일시정지\")\n",
    "        print(\"  'A' 또는 Left Arrow: 이전 프레임\")\n",
    "        print(\"  'D' 또는 Right Arrow: 다음 프레임\")\n",
    "        print(\"  'W' 또는 Up Arrow: 재생 속도 증가\")\n",
    "        print(\"  'S' 또는 Down Arrow: 재생 속도 감소\")\n",
    "        print(\"  'R': 카메라 뷰 초기화\")\n",
    "        print(\"  'Q': 시각화 종료\")\n",
    "        print(\"---------------------------------------------\")\n",
    "\n",
    "        self._update_geometry_for_frame(self.current_frame_idx)\n",
    "\n",
    "    def _on_layout(self, layout_context):\n",
    "        r = self.window.content_rect\n",
    "        # SceneWidget의 frame 속성을 설정하면, 내부적으로 씬의 뷰포트와 크기를 자동으로 조절합니다.\n",
    "        # 따라서 self.scene.set_view_size나 self.scene.set_viewport는 더 이상 필요하지 않습니다.\n",
    "        self.scene_widget.frame = r\n",
    "        # self.scene.set_view_size(r.width, r.height) # 제거\n",
    "        # self.scene.set_viewport(r.x, r.y, r.width, r.height) # 제거\n",
    "\n",
    "    def _initialize_geometry(self):\n",
    "        initial_landmarks = self.all_frames_3d_landmarks[0]\n",
    "\n",
    "        self.point_cloud_geometry = o3d.geometry.PointCloud()\n",
    "        self.point_cloud_geometry.points = o3d.utility.Vector3dVector(initial_landmarks)\n",
    "        self.point_cloud_geometry.colors = o3d.utility.Vector3dVector(\n",
    "            np.array([[1.0, 0.0, 0.0] for _ in range(initial_landmarks.shape[0])])\n",
    "        )\n",
    "\n",
    "        lines = []\n",
    "        line_colors = []\n",
    "        for c_tuple in self.connections:\n",
    "            lines.append([c_tuple[0], c_tuple[1]])\n",
    "            mapped_color = None\n",
    "            for conn_key, color_rgb in CONNECTIONS_COLORS.items():\n",
    "                if (conn_key[0] == c_tuple[0] and conn_key[1] == c_tuple[1]) or \\\n",
    "                   (conn_key[0] == c_tuple[1] and conn_key[1] == c_tuple[0]):\n",
    "                    mapped_color = [x / 255.0 for x in color_rgb]\n",
    "                    break\n",
    "            line_colors.append(mapped_color if mapped_color else [1.0, 1.0, 1.0])\n",
    "\n",
    "        self.line_set_geometry = o3d.geometry.LineSet()\n",
    "        self.line_set_geometry.points = o3d.utility.Vector3dVector(initial_landmarks)\n",
    "        self.line_set_geometry.lines = o3d.utility.Vector2iVector(lines)\n",
    "        self.line_set_geometry.colors = o3d.utility.Vector3dVector(np.array(line_colors))\n",
    "\n",
    "        red_material = o3d.visualization.rendering.MaterialRecord()\n",
    "        red_material.base_color = [1.0, 0.0, 0.0, 1.0]\n",
    "        red_material.shader = \"defaultLit\"\n",
    "\n",
    "        white_material = o3d.visualization.rendering.MaterialRecord()\n",
    "        white_material.base_color = [1.0, 1.0, 1.0, 1.0]\n",
    "        white_material.shader = \"defaultLit\"\n",
    "\n",
    "        self.scene_widget.scene.add_geometry(self.pcd_name, self.point_cloud_geometry, red_material)\n",
    "        self.scene_widget.scene.add_geometry(self.line_set_name, self.line_set_geometry, white_material)\n",
    "\n",
    "    def _update_geometry_for_frame(self, frame_idx):\n",
    "        if not (0 <= frame_idx < self.num_frames):\n",
    "            print(f\"경고: 프레임 인덱스 {frame_idx}가 범위를 벗어났습니다 (0-{self.num_frames-1}).\")\n",
    "            return\n",
    "\n",
    "        frame_landmarks_3d = self.all_frames_3d_landmarks[frame_idx]\n",
    "\n",
    "        self.point_cloud_geometry.points = o3d.utility.Vector3dVector(frame_landmarks_3d)\n",
    "        # self.point_cloud_geometry.colors = o3d.utility.Vector3dVector(\n",
    "        #     np.array([[1.0, 0.0, 0.0] for _ in range(frame_landmarks_3d.shape[0])])\n",
    "        # )\n",
    "\n",
    "        self.line_set_geometry.points = o3d.utility.Vector3dVector(frame_landmarks_3d)\n",
    "\n",
    "    def update_frame_delay(self):\n",
    "        self.current_frame_delay = self.base_frame_delay / max(0.01, self.playback_speed_factor)\n",
    "\n",
    "    def _on_key_event(self, event):\n",
    "        if event.type == o3d.visualization.gui.KeyEvent.Type.DOWN:\n",
    "            key_code = event.key\n",
    "            if key_code == o3d.visualization.gui.Key.SPACE:\n",
    "                self._toggle_play_pause()\n",
    "            elif key_code == o3d.visualization.gui.Key.A or key_code == o3d.visualization.gui.Key.LEFT:\n",
    "                self._prev_frame()\n",
    "            elif key_code == o3d.visualization.gui.Key.D or key_code == o3d.visualization.gui.Key.RIGHT:\n",
    "                self._next_frame()\n",
    "            elif key_code == o3d.visualization.gui.Key.W or key_code == o3d.visualization.gui.Key.UP:\n",
    "                self._speed_up()\n",
    "            elif key_code == o3d.visualization.gui.Key.S or key_code == o3d.visualization.gui.Key.DOWN:\n",
    "                self._slow_down()\n",
    "            elif key_code == o3d.visualization.gui.Key.R:\n",
    "                self._reset_view()\n",
    "            elif key_code == o3d.visualization.gui.Key.Q:\n",
    "                self.window.close()\n",
    "            return o3d.visualization.gui.Widget.EventCallbackResult.HANDLED\n",
    "        return o3d.visualization.gui.Widget.EventCallbackResult.IGNORED\n",
    "\n",
    "    def _toggle_play_pause(self):\n",
    "        self.is_playing = not self.is_playing\n",
    "        print(f\"애니메이션: {'재생 중' if self.is_playing else '일시 정지'}\")\n",
    "\n",
    "    def _next_frame(self):\n",
    "        self.is_playing = False # 수동 프레임 이동 시 재생 중지\n",
    "        self.current_frame_idx = (self.current_frame_idx + 1) % self.num_frames\n",
    "        self._update_geometry_for_frame(self.current_frame_idx)\n",
    "        self.app.post_redraw() # 수동 프레임 이동 후 즉시 갱신 요청\n",
    "\n",
    "    def _prev_frame(self):\n",
    "        self.is_playing = False # 수동 프레임 이동 시 재생 중지\n",
    "        self.current_frame_idx = (self.current_frame_idx - 1 + self.num_frames) % self.num_frames\n",
    "        self._update_geometry_for_frame(self.current_frame_idx)\n",
    "        self.app.post_redraw() # 수동 프레임 이동 후 즉시 갱신 요청\n",
    "\n",
    "    def _speed_up(self):\n",
    "        self.playback_speed_factor *= 1.2\n",
    "        self.update_frame_delay()\n",
    "        print(f\"재생 속도: {self.playback_speed_factor:.2f}배\")\n",
    "\n",
    "    def _slow_down(self):\n",
    "        self.playback_speed_factor /= 1.2\n",
    "        if self.playback_speed_factor < 0.1: self.playback_speed_factor = 0.1\n",
    "        self.update_frame_delay()\n",
    "        print(f\"재생 속도: {self.playback_speed_factor:.2f}배\")\n",
    "\n",
    "    def _reset_view(self):\n",
    "        self.scene_widget.setup_camera(1.0, self.scene_bbox, [0, 0, -1])\n",
    "        self.app.post_redraw() # 카메라 뷰 변경 후 즉시 갱신 요청\n",
    "        print(\"카메라 뷰 초기화.\")\n",
    "\n",
    "    def run(self):\n",
    "        # 이 함수는 post_to_main_thread에 의해 반복적으로 호출됩니다.\n",
    "        def update_animation_loop():\n",
    "            current_time = time.time()\n",
    "            if self.is_playing and (current_time - self.last_frame_time) >= self.current_frame_delay:\n",
    "                self.current_frame_idx = (self.current_frame_idx + 1) % self.num_frames\n",
    "                self._update_geometry_for_frame(self.current_frame_idx)\n",
    "                self.last_frame_time = current_time\n",
    "                self.app.post_redraw() # 프레임 업데이트 후 다시 그리도록 요청\n",
    "\n",
    "            # 애니메이션 루프를 계속 실행하기 위해 이 함수를 다시 스케줄링합니다.\n",
    "            self.app.post_to_main_thread(self.window, update_animation_loop)\n",
    "\n",
    "        self.last_frame_time = time.time()\n",
    "        # 애니메이션 루프의 첫 호출을 스케줄링하여 시작합니다.\n",
    "        self.app.post_to_main_thread(self.window, update_animation_loop)\n",
    "        \n",
    "        self.app.run()\n",
    "        self.app.quit()\n",
    "        print(\"3D 인터랙티브 시각화가 종료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71181336-7710-42fc-aa44-3f52cc33c0f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 맞춤형 툴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ae73a-ed93-4f05-b25a-7ccd7c76656d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 관절 이름 맵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49733624-ff72-453b-9a68-e72176fb2ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_joints(landmarks):\n",
    "     return { \"R_shoulder\": landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "                \"R_elbow\": landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW],\n",
    "                \"R_wrist\": landmarks[mp_pose.PoseLandmark.RIGHT_WRIST],\n",
    "                \"R_hip\": landmarks[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "                \"R_knee\": landmarks[mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "                \"R_ankle\": landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE],\n",
    "                \"L_shoulder\": landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "                \"L_elbow\": landmarks[mp_pose.PoseLandmark.LEFT_ELBOW],\n",
    "                \"L_wrist\": landmarks[mp_pose.PoseLandmark.LEFT_WRIST],\n",
    "                \"L_hip\": landmarks[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "                \"L_knee\": landmarks[mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "                \"L_ankle\": landmarks[mp_pose.PoseLandmark.LEFT_ANKLE],\n",
    "                \"R_pinky_tip\": landmarks[mp_pose.PoseLandmark.RIGHT_INDEX],\n",
    "                \"L_pinky_tip\": landmarks[mp_pose.PoseLandmark.LEFT_INDEX]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58ed3a7-44c3-4e0b-874b-0632a42a562c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 각도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686d4d75-48ee-4592-b62a-785b8c872578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(vec1, vec2):\n",
    "    # 코사인 값 계산\n",
    "    # np.dot(ba, bc)는 내적, np.linalg.norm()은 벡터의 크기\n",
    "    cosine_angle = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "    # 아크코사인으로 라디안 각도 계산\n",
    "    angle_radians = np.arccos(np.clip(cosine_angle, -1.0, 1.0)) # clip으로 부동 소수점 오차 방지\n",
    "\n",
    "    # 라디안을 도로 변환\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "    return angle_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be629867-0387-4a4e-b2ea-3b1eef2a1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_3(a, b, c):\n",
    "\n",
    "    return calculate_angle(a - b, c - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "393f971f-e1ca-4ce0-9b8d-9bfd2ac382cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle_4(a, b, c, d):\n",
    "    v1 = np.array([a[0] - b[0], a[2] - b[2]]);\n",
    "    v2 = np.array([c[0] - d[0], c[2] - d[2]])\n",
    "    \n",
    "    # 아크코사인으로 라디안 각도 계산\n",
    "    angle_radians = np.arctan2(v1[0]*v2[1] - v1[1]*v2[0], v1[0]*v2[0] + v1[1]*v2[1])\n",
    "    angle_degrees = np.degrees(angle_radians)\n",
    "\n",
    "    return angle_degrees\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f971854-e182-4c3e-9883-44343809159c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 투수용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11db5c18-b2af-4b69-80d3-234a67cd4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitcher_tool(landmarks):\n",
    "\n",
    "    joints = get_joints(landmarks)\n",
    "    \n",
    "    # --- 각도 계산 ---\n",
    "    # 1. 오른쪽 팔꿈치 각도\n",
    "    angle_R_elbow = calculate_angle_3(joints[\"R_shoulder\"], joints[\"R_elbow\"], joints[\"R_wrist\"])\n",
    "    angle_L_elbow = calculate_angle_3(joints[\"L_shoulder\"], joints[\"L_elbow\"], joints[\"L_wrist\"])\n",
    "\n",
    "    # 2. 오른쪽 어깨 각도 (몸통-어깨-팔꿈치\"])\n",
    "    angle_R_shoulder = calculate_angle_3(joints[\"L_shoulder\"], joints[\"R_shoulder\"], joints[\"R_elbow\"])\n",
    "    angle_L_shoulder = calculate_angle_3(joints[\"R_shoulder\"], joints[\"L_shoulder\"], joints[\"L_elbow\"])\n",
    "\n",
    "    # 3. 오른쪽 골반 각도 (몸통-골반-무릎\"])\n",
    "    angle_body_twist = calculate_angle_4(joints[\"R_shoulder\"], joints[\"L_shoulder\"], joints[\"R_hip\"], joints[\"L_hip\"])\n",
    "\n",
    "    # 4. 오른쪽 무릎 각도\n",
    "    angle_R_knee = calculate_angle_3(joints[\"R_hip\"], joints[\"R_knee\"], joints[\"R_ankle\"])\n",
    "    angle_L_knee = calculate_angle_3(joints[\"L_hip\"], joints[\"L_knee\"], joints[\"L_ankle\"])\n",
    "\n",
    "    return [ [\"R Elbow\", str(round(angle_R_elbow, 2))],\n",
    "          [\"L Elbow\", str(round(angle_L_elbow, 2))],\n",
    "          [\"R Shoulder\", str(round(angle_R_shoulder, 2))],\n",
    "          [\"L Shoulder\", str(round(angle_L_shoulder, 2))],\n",
    "          [\"Body Twist\", str(round(angle_body_twist, 2))],\n",
    "          [\"R Knee\", str(round(angle_R_knee, 2))],\n",
    "          [\"L Knee\", str(round(angle_L_knee, 2))]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b16141-3f8c-4ee1-bebb-1e3ce6cd8e9b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 타자용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a5ffce-a374-4a4d-b6d1-8d3b742e5f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batter_tool(landmarks):\n",
    "    joints = get_joints(landmarks)\n",
    "    \n",
    "    # --- 각도 계산 ---\n",
    "    # 1. 팔꿈치 각도\n",
    "    angle_R_elbow = calculate_angle_3(joints[\"R_shoulder\"], joints[\"R_elbow\"], joints[\"R_wrist\"])\n",
    "    angle_L_elbow = calculate_angle_3(joints[\"L_shoulder\"], joints[\"L_elbow\"], joints[\"L_wrist\"])\n",
    "\n",
    "    # 2. 어깨 각도\n",
    "    angle_R_shoulder = calculate_angle_3(joints[\"L_shoulder\"], joints[\"R_shoulder\"], joints[\"R_elbow\"])\n",
    "    angle_L_shoulder = calculate_angle_3(joints[\"R_shoulder\"], joints[\"L_shoulder\"], joints[\"L_elbow\"])\n",
    "\n",
    "    # 3. 꼬임\n",
    "    angle_body_twist = calculate_angle_4(joints[\"R_shoulder\"], joints[\"L_shoulder\"], joints[\"R_hip\"], joints[\"L_hip\"])\n",
    "\n",
    "    # 4. 무릎 각도\n",
    "    angle_R_knee = calculate_angle_3(joints[\"R_hip\"], joints[\"R_knee\"], joints[\"R_ankle\"])\n",
    "    angle_L_knee = calculate_angle_3(joints[\"L_hip\"], joints[\"L_knee\"], joints[\"L_ankle\"])\n",
    "    \n",
    "    angle_R_wrist = calculate_angle_3(joints[\"R_elbow\"], joints[\"R_wrist\"], joints[\"R_pinky_tip\"])\n",
    "    angle_L_wrist = calculate_angle_3(joints[\"L_elbow\"], joints[\"L_wrist\"], joints[\"L_pinky_tip\"])\n",
    "\n",
    "    return [ [\"R Elbow\", str(round(angle_R_elbow, 2))],\n",
    "          [\"L Elbow\", str(round(angle_L_elbow, 2))],\n",
    "          [\"R Shoulder\", str(round(angle_R_shoulder, 2))],\n",
    "          [\"L Shoulder\", str(round(angle_L_shoulder, 2))],\n",
    "          [\"Body Twist\", str(round(angle_body_twist, 2))],\n",
    "          [\"R Knee\", str(round(angle_R_knee, 2))],\n",
    "          [\"L Knee\", str(round(angle_L_knee, 2))],\n",
    "          [\"R wrist\", str(round(angle_R_wrist, 2))],\n",
    "          [\"L wrist\", str(round(angle_L_wrist, 2))]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd3662-9faf-4dad-97d4-9ed98f1ec714",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 칼만 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2381415-c0f2-4145-ba2f-62b7809185ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칼만 필터 클래스 (새로 추가)\n",
    "class LandmarkKalmanFilter:\n",
    "    def __init__(self, num_landmarks=33, dim_state=6, dim_measurement=3, dt=1.0, process_noise_std=0.01, measurement_noise_std=0.1):\n",
    "        # dim_state: 상태 벡터의 차원 (x, y, z, vx, vy, vz) = 6\n",
    "        # dim_measurement: 측정 벡터의 차원 (x, y, z) = 3\n",
    "        # dt: 시간 간격 (여기서는 프레임 간 간격, 1로 가정)\n",
    "        \n",
    "        self.filters = []\n",
    "        for _ in range(num_landmarks):\n",
    "            kf = KalmanFilter(dim_x=dim_state, dim_z=dim_measurement)\n",
    "\n",
    "            # 상태 전이 행렬 (F): x = x + vx*dt, y = y + vy*dt, z = z + vz*dt\n",
    "            kf.F = np.array([[1, 0, 0, dt, 0, 0],\n",
    "                             [0, 1, 0, 0, dt, 0],\n",
    "                             [0, 0, 1, 0, 0, dt],\n",
    "                             [0, 0, 0, 1, 0, 0],\n",
    "                             [0, 0, 0, 0, 1, 0],\n",
    "                             [0, 0, 0, 0, 0, 1]])\n",
    "\n",
    "            # 측정 행렬 (H): 측정값은 상태 벡터의 (x, y, z) 부분\n",
    "            kf.H = np.array([[1, 0, 0, 0, 0, 0],\n",
    "                             [0, 1, 0, 0, 0, 0],\n",
    "                             [0, 0, 1, 0, 0, 0]])\n",
    "\n",
    "            # 공분산 행렬 (P): 초기 상태 불확실성 (클수록 초기 수렴 빠름)\n",
    "            kf.P *= 1000.\n",
    "\n",
    "            # 프로세스 노이즈 공분산 (Q): 모델 예측의 불확실성 (높을수록 필터가 측정값에 더 민감)\n",
    "            # 랜드마크 움직임의 불확실성이 크다면 높게 설정 (예: 0.01)\n",
    "            kf.Q = np.diag([process_noise_std**2]*3 + [process_noise_std**2]*3) # x,y,z 및 vx,vy,vz에 대한 노이즈\n",
    "\n",
    "            # 측정 노이즈 공분산 (R): 측정값의 불확실성 (높을수록 필터가 측정값을 덜 신뢰)\n",
    "            # MediaPipe 랜드마크의 노이즈가 심하면 높게 설정 (예: 0.1)\n",
    "            kf.R = np.diag([measurement_noise_std**2]*3) # x,y,z 측정 노이즈\n",
    "\n",
    "            # 초기 상태 벡터 (x): [x, y, z, vx, vy, vz]\n",
    "            kf.x = np.zeros((dim_state, 1)) # 초기값은 첫 측정값으로 설정\n",
    "\n",
    "            self.filters.append(kf)\n",
    "        self.initialized = False # 필터 초기화 여부 플래그\n",
    "\n",
    "    def initialize_state(self, first_landmarks_coords):\n",
    "        # 첫 프레임에서 모든 랜드마크의 초기 상태를 설정 (측정값으로)\n",
    "        for i, kf in enumerate(self.filters):\n",
    "            if i < len(first_landmarks_coords): # 유효한 랜드마크 개수 범위 내에서\n",
    "                # x, y, z는 첫 측정값으로, 속도(vx,vy,vz)는 0으로 초기화\n",
    "                kf.x = np.array([[first_landmarks_coords[i][0]],\n",
    "                                 [first_landmarks_coords[i][1]],\n",
    "                                 [first_landmarks_coords[i][2]],\n",
    "                                 [0.], [0.], [0.]])\n",
    "        self.initialized = True\n",
    "\n",
    "    def filter(self, current_landmarks_coords, visibility_scores=None, min_visibility_threshold=0.5):\n",
    "        # current_landmarks_coords: 현재 프레임의 (num_landmarks, 3) numpy 배열\n",
    "        # visibility_scores: 현재 프레임의 (num_landmarks,) numpy 배열 (0~1)\n",
    "        \n",
    "        filtered_coords = np.zeros_like(current_landmarks_coords)\n",
    "        for i, kf in enumerate(self.filters):\n",
    "            # predict 단계\n",
    "            kf.predict()\n",
    "            \n",
    "            # update 단계: visibility 점수 기반으로 측정값 사용 여부 결정\n",
    "            if visibility_scores is not None and visibility_scores[i] < min_visibility_threshold:\n",
    "                # 랜드마크가 충분히 보이지 않으면 측정값을 사용하지 않고 예측값만 사용\n",
    "                filtered_coords[i] = kf.x[:3].flatten() # 상태 벡터의 위치 부분만 사용\n",
    "            else:\n",
    "                # 랜드마크가 잘 보이면 측정값으로 업데이트\n",
    "                kf.update(current_landmarks_coords[i].reshape(-1, 1))\n",
    "                filtered_coords[i] = kf.x[:3].flatten()\n",
    "\n",
    "        return filtered_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f714510-5e9c-43ed-a7b0-a0bf7c0daaeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 작동 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3de3b147-2aaf-4334-b886-baa51514158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_recognize_func(video_path, video_prename, tool):\n",
    "    print(\"MediaPipe Pose를 초기화합니다...\")\n",
    "    with mp_pose.Pose(\n",
    "        static_image_mode=False,\n",
    "        model_complexity=model_complexity,\n",
    "        enable_segmentation=False,\n",
    "        min_detection_confidence=min_detection_confidence,\n",
    "        min_tracking_confidence=min_tracking_confidence) as pose:\n",
    "\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"오류: 비디오 파일 {video_path}를 열 수 없습니다.\")\n",
    "            return\n",
    "\n",
    "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        combined_out = cv2.VideoWriter(os.path.join(output_dir, video_prename + '_combined_output.mp4'), fourcc, fps, (frame_width, frame_height))\n",
    "        bone_out = cv2.VideoWriter(os.path.join(output_dir, video_prename + '_bone_output.mp4'), fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        if not combined_out.isOpened() or not bone_out.isOpened():\n",
    "            print(\"오류: 출력 비디오 파일을 생성할 수 없습니다. 코덱 또는 권한을 확인하세요.\")\n",
    "            cap.release()\n",
    "            return\n",
    "\n",
    "        all_frames_3d_landmarks = [] # 원본 (필터링 전) 랜드마크 저장용\n",
    "        all_frames_filtered_3d_landmarks = [] # 필터링 후 랜드마크 저장용\n",
    "        \n",
    "        frame_count = 0\n",
    "        progress_interval = max(1, total_frames // 100) # 진행률 표시를 위한 간격\n",
    "\n",
    "        # 칼만 필터 초기화\n",
    "        # MediaPipe Pose는 33개의 랜드마크를 가집니다.\n",
    "        # process_noise_std와 measurement_noise_std 값은 튜닝이 필요할 수 있습니다.\n",
    "        # 더 작은 값은 더 부드러운 결과를, 더 큰 값은 측정값에 더 빠르게 반응합니다.\n",
    "        kalman_filter_processor = LandmarkKalmanFilter(\n",
    "            num_landmarks=33, \n",
    "            process_noise_std=kalman_filter_process_noise_std,  # 프로세스 노이즈 표준 편차 (낮을수록 예측 신뢰)\n",
    "            measurement_noise_std=kalman_filter_measurement_noise_std # 측정 노이즈 표준 편차 (낮을수록 측정 신뢰)\n",
    "        )\n",
    "        min_visibility_threshold = 0.6 # 랜드마크 가려짐 임계값\n",
    "\n",
    "        print(\"비디오 처리 시작...\")\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read() # 프레임 읽기\n",
    "            if not ret:\n",
    "                if total_frames > 0:\n",
    "                    sys.stdout.write(f\"\\r처리 중: 100.00% ({total_frames}/{total_frames} 프레임)\")\n",
    "                    sys.stdout.flush()\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            # 진행률 표시\n",
    "            if total_frames > 0 and (frame_count == 1 or frame_count % progress_interval == 0 or frame_count == total_frames):\n",
    "                progress_percent = (frame_count / total_frames) * 100\n",
    "                sys.stdout.write(f\"\\r처리 중: {progress_percent:.2f}% ({frame_count}/{total_frames} 프레임)\")\n",
    "                sys.stdout.flush()\n",
    "\n",
    "            # MediaPipe Pose 처리\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_rgb.flags.writeable = False\n",
    "            results = pose.process(frame_rgb)\n",
    "            frame_rgb.flags.writeable = True\n",
    "\n",
    "            frame_with_pose = frame.copy()\n",
    "\n",
    "            if results.pose_landmarks:\n",
    "                # 월드 랜드마크 (3D 좌표) 추출\n",
    "                current_raw_3d_landmarks_array = np.array([\n",
    "                    [lmk.x, lmk.y, lmk.z]\n",
    "                    for lmk in results.pose_world_landmarks.landmark\n",
    "                ])\n",
    "                all_frames_3d_landmarks.append(current_raw_3d_landmarks_array) # 원본 저장\n",
    "\n",
    "                if apply_kalman_filter:\n",
    "                    # 랜드마크 visibility (시야) 점수 추출\n",
    "                    visibility_scores = np.array([lmk.visibility for lmk in results.pose_world_landmarks.landmark])\n",
    "    \n",
    "                    # 칼만 필터 초기화 또는 필터링\n",
    "                    if not kalman_filter_processor.initialized:\n",
    "                        kalman_filter_processor.initialize_state(current_raw_3d_landmarks_array)\n",
    "                        filtered_landmarks_array = current_raw_3d_landmarks_array # 초기 프레임은 원본 그대로\n",
    "                    else:\n",
    "                        filtered_landmarks_array = kalman_filter_processor.filter(\n",
    "                            current_raw_3d_landmarks_array, \n",
    "                            visibility_scores=visibility_scores, \n",
    "                            min_visibility_threshold=min_visibility_threshold\n",
    "                        )\n",
    "                else:\n",
    "                    filtered_landmarks_array = current_raw_3d_landmarks_array\n",
    "                        \n",
    "                all_frames_filtered_3d_landmarks.append(filtered_landmarks_array) # 필터링된 랜드마크 저장\n",
    "\n",
    "                # 필터링된 랜드마크를 사용하여 2D 포즈를 프레임에 그리기 (선택 사항: 원본으로 그릴 수도 있음)\n",
    "                # 랜드마크를 그리기 위해 MediaPipe Drawing Spec에 다시 매핑해야 할 수 있습니다.\n",
    "                # 여기서는 원본 랜드마크 결과를 사용하고, 계산만 필터링된 랜드마크로 합니다.\n",
    "                frame_with_pose = draw_pose_on_frame(frame_with_pose, results.pose_landmarks)\n",
    "                \n",
    "                strs = tool(filtered_landmarks_array) \n",
    "\n",
    "                for i in range(len(strs)):\n",
    "                    cv2.putText(frame_with_pose, strs[i][0] + \": \" + strs[i][1], (10, frame.shape[0] - i * 15 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "                    \n",
    "            # 결과 비디오 파일에 쓰기\n",
    "            combined_out.write(frame_with_pose)\n",
    "            final_pose_only_frame = only_bone(frame, frame_with_pose) # 이 함수도 필터링된 랜드마크로 그릴지 결정\n",
    "            bone_out.write(final_pose_only_frame)\n",
    "\n",
    "    print(\"\\n비디오 객체를 해제합니다...\")\n",
    "    combined_out.release()\n",
    "    bone_out.release()\n",
    "    cap.release()\n",
    "\n",
    "    # 필터링된 랜드마크와 FPS 반환\n",
    "    return all_frames_filtered_3d_landmarks, fps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cdcde-97e0-4f0c-b6d9-a627a0e8ca61",
   "metadata": {},
   "source": [
    "# 실행 부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c811c08c-3c72-4a60-b13f-288ad05c6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe Pose를 초기화합니다...\n",
      "비디오 처리 시작...\n",
      "처리 중: 100.00% (661/661 프레임)\n",
      "비디오 객체를 해제합니다...\n"
     ]
    }
   ],
   "source": [
    "target_name = \"이지헌1\"\n",
    "video_name = \"raw_data/\" + target_name + \".mov\"\n",
    "all_frames_3d_landmarks, fps = pose_recognize_func(video_name, target_name, batter_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d172da95-07d1-488a-8e5c-55d644ecba56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting 3D data to C3D file...\n",
      "총 179 프레임을 result_data\\이진우_3d_pose.c3d으로 성공적으로 내보냈습니다.\n",
      "C3D export complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\Anaconda\\Lib\\site-packages\\c3d\\c3d.py:1210: UserWarning: missing parameter POINT:LABELS\n",
      "  warnings.warn('missing parameter {}'.format(name))\n",
      "C:\\Temp\\Anaconda\\Lib\\site-packages\\c3d\\c3d.py:1219: UserWarning: No analog data found in file.\n",
      "  warnings.warn('No analog data found in file.')\n"
     ]
    }
   ],
   "source": [
    "# --- Export 3D data to C3D file ---\n",
    "print(\"\\nExporting 3D data to C3D file...\")\n",
    "c3d_output_path = os.path.join(output_dir, target_name + '_3d_pose.c3d')\n",
    "export_to_c3d(c3d_output_path, all_frames_3d_landmarks, fps, ALL_POSE_MARKER_NAMES)\n",
    "print(\"C3D export complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468419b2-1816-4343-ae2f-517e90404285",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_viz = InteractivePoseVisualizer(all_frames_3d_landmarks, mp_pose.POSE_CONNECTIONS, fps)\n",
    "#interactive_viz.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc8611-1af0-42ca-b03f-183d49aab381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import open3d.visualization.gui as gui\n",
    "import open3d.visualization.rendering as rendering\n",
    "\n",
    "\n",
    "app = gui.Application.instance\n",
    "app.initialize()\n",
    "\n",
    "window = app.create_window(\"Hello Open3D\", 1024, 768)\n",
    "\n",
    "# 씬 위젯 생성 및 추가\n",
    "scene_widget = gui.SceneWidget()\n",
    "scene_widget.scene = rendering.Open3DScene(window.renderer)\n",
    "window.add_child(scene_widget)\n",
    "\n",
    "# 카메라 설정\n",
    "scene_widget.setup_camera(60, window.content_rect.width / window.content_rect.height,\n",
    "                             o3d.geometry.AxisAlignedBoundingBox([-1, -1, -1], [1, 1, 1]))\n",
    "\n",
    "    # 간단한 메시 추가\n",
    "mesh = o3d.geometry.TriangleMesh.create_sphere()\n",
    "mesh.compute_vertex_normals()\n",
    "    \n",
    "mat = rendering.MaterialRecord()\n",
    "mat.shader = \"defaultLit\"\n",
    "mat.base_color = [0.8, 0.8, 0.8, 1.0] # 회색\n",
    "\n",
    "scene_widget.scene.add_geometry(\"sphere\", mesh, mat)\n",
    "\n",
    "# 레이아웃 설정\n",
    "window.set_on_layout(lambda layout_context: scene_widget.set_frame(window.content_rect))\n",
    "\n",
    "app.run()\n",
    "app.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
